16/05/02 01:57:59 INFO spark.SparkContext: Running Spark version 1.6.1
16/05/02 01:57:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/05/02 01:58:00 INFO spark.SecurityManager: Changing view acls to: root
16/05/02 01:58:00 INFO spark.SecurityManager: Changing modify acls to: root
16/05/02 01:58:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
16/05/02 01:58:00 INFO util.Utils: Successfully started service 'sparkDriver' on port 46359.
16/05/02 01:58:00 INFO slf4j.Slf4jLogger: Slf4jLogger started
16/05/02 01:58:00 INFO Remoting: Starting remoting
16/05/02 01:58:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.17.0.3:35289]
16/05/02 01:58:01 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 35289.
16/05/02 01:58:01 INFO spark.SparkEnv: Registering MapOutputTracker
16/05/02 01:58:01 INFO spark.SparkEnv: Registering BlockManagerMaster
16/05/02 01:58:01 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-8bfe8bda-da49-4f21-a1a5-15c8b9aeb892
16/05/02 01:58:01 INFO storage.MemoryStore: MemoryStore started with capacity 511.1 MB
16/05/02 01:58:01 INFO spark.SparkEnv: Registering OutputCommitCoordinator
16/05/02 01:58:01 INFO server.Server: jetty-8.y.z-SNAPSHOT
16/05/02 01:58:01 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
16/05/02 01:58:01 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
16/05/02 01:58:01 INFO ui.SparkUI: Started SparkUI at http://172.17.0.3:4040
16/05/02 01:58:01 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8b650f5f-e411-46bb-b93e-b0d8a1c54200/httpd-6ab0461a-9644-45d1-a3e2-057385a40ada
16/05/02 01:58:01 INFO spark.HttpServer: Starting HTTP Server
16/05/02 01:58:01 INFO server.Server: jetty-8.y.z-SNAPSHOT
16/05/02 01:58:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37177
16/05/02 01:58:01 INFO util.Utils: Successfully started service 'HTTP file server' on port 37177.
16/05/02 01:58:01 INFO util.Utils: Copying /tmp/data/main.py to /tmp/spark-8b650f5f-e411-46bb-b93e-b0d8a1c54200/userFiles-8810a7c7-c5ec-47f1-8faf-1c66418a2d1e/main.py
16/05/02 01:58:01 INFO spark.SparkContext: Added file file:/tmp/data/main.py at http://172.17.0.3:37177/files/main.py with timestamp 1462154281860
16/05/02 01:58:01 INFO client.AppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
16/05/02 01:58:02 INFO cluster.SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20160502015802-0021
16/05/02 01:58:02 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36614.
16/05/02 01:58:02 INFO client.AppClient$ClientEndpoint: Executor added: app-20160502015802-0021/0 on worker-20160502011255-172.17.0.4-8881 (172.17.0.4:8881) with 2 cores
16/05/02 01:58:02 INFO cluster.SparkDeploySchedulerBackend: Granted executor ID app-20160502015802-0021/0 on hostPort 172.17.0.4:8881 with 2 cores, 512.0 MB RAM
16/05/02 01:58:02 INFO netty.NettyBlockTransferService: Server created on 36614
16/05/02 01:58:02 INFO storage.BlockManagerMaster: Trying to register BlockManager
16/05/02 01:58:02 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.3:36614 with 511.1 MB RAM, BlockManagerId(driver, 172.17.0.3, 36614)
16/05/02 01:58:02 INFO storage.BlockManagerMaster: Registered BlockManager
16/05/02 01:58:02 INFO client.AppClient$ClientEndpoint: Executor updated: app-20160502015802-0021/0 is now RUNNING
16/05/02 01:58:02 INFO cluster.SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
16/05/02 01:58:03 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.6 KB, free 208.6 KB)
16/05/02 01:58:03 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.5 KB, free 228.0 KB)
16/05/02 01:58:03 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.3:36614 (size: 19.5 KB, free: 511.1 MB)
16/05/02 01:58:03 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
16/05/02 01:58:03 INFO mapred.FileInputFormat: Total input paths to process : 1
16/05/02 01:58:03 INFO spark.SparkContext: Starting job: collect at /tmp/data/main.py:5
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Registering RDD 3 (groupByKey at /tmp/data/main.py:19)
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Got job 0 (collect at /tmp/data/main.py:5) with 2 output partitions
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (collect at /tmp/data/main.py:5)
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /tmp/data/main.py:19), which has no missing parents
16/05/02 01:58:03 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.1 KB, free 236.1 KB)
16/05/02 01:58:03 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 241.4 KB)
16/05/02 01:58:03 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.3:36614 (size: 5.3 KB, free: 511.1 MB)
16/05/02 01:58:03 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:03 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /tmp/data/main.py:19)
16/05/02 01:58:03 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/05/02 01:58:05 INFO cluster.SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (172.17.0.4:54084) with ID 0
16/05/02 01:58:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.17.0.4, partition 0,PROCESS_LOCAL, 2163 bytes)
16/05/02 01:58:05 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 172.17.0.4, partition 1,PROCESS_LOCAL, 2163 bytes)
16/05/02 01:58:05 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.17.0.4:46195 with 143.3 MB RAM, BlockManagerId(0, 172.17.0.4, 46195)
16/05/02 01:58:05 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.17.0.4:46195 (size: 5.3 KB, free: 143.2 MB)
16/05/02 01:58:06 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.17.0.4:46195 (size: 19.5 KB, free: 143.2 MB)
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1402 ms on 172.17.0.4 (1/2)
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1367 ms on 172.17.0.4 (2/2)
16/05/02 01:58:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/05/02 01:58:06 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (groupByKey at /tmp/data/main.py:19) finished in 3.267 s
16/05/02 01:58:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
16/05/02 01:58:06 INFO scheduler.DAGScheduler: running: Set()
16/05/02 01:58:06 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
16/05/02 01:58:06 INFO scheduler.DAGScheduler: failed: Set()
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (PythonRDD[6] at collect at /tmp/data/main.py:5), which has no missing parents
16/05/02 01:58:06 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.8 KB, free 247.1 KB)
16/05/02 01:58:06 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 250.9 KB)
16/05/02 01:58:06 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.3:36614 (size: 3.8 KB, free: 511.1 MB)
16/05/02 01:58:06 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[6] at collect at /tmp/data/main.py:5)
16/05/02 01:58:06 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, 172.17.0.4, partition 0,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, 172.17.0.4, partition 1,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:06 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.17.0.4:46195 (size: 3.8 KB, free: 143.2 MB)
16/05/02 01:58:06 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.17.0.4:54084
16/05/02 01:58:06 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 150 bytes
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 141 ms on 172.17.0.4 (1/2)
16/05/02 01:58:06 INFO scheduler.DAGScheduler: ResultStage 1 (collect at /tmp/data/main.py:5) finished in 0.147 s
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 148 ms on 172.17.0.4 (2/2)
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Job 0 finished: collect at /tmp/data/main.py:5, took 3.622658 s
16/05/02 01:58:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
('user_0', <pyspark.resultiterable.ResultIterable object at 0x7f72ae07f0b8>)
step2: (user_id, [item])
16/05/02 01:58:06 INFO spark.SparkContext: Starting job: collect at /tmp/data/main.py:5
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Got job 1 (collect at /tmp/data/main.py:5) with 2 output partitions
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (collect at /tmp/data/main.py:5)
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Missing parents: List()
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (PythonRDD[7] at collect at /tmp/data/main.py:5), which has no missing parents
16/05/02 01:58:06 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.4 KB, free 257.3 KB)
16/05/02 01:58:06 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.2 KB, free 261.5 KB)
16/05/02 01:58:06 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.3:36614 (size: 4.2 KB, free: 511.1 MB)
16/05/02 01:58:06 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:06 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[7] at collect at /tmp/data/main.py:5)
16/05/02 01:58:06 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, 172.17.0.4, partition 0,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:06 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, 172.17.0.4, partition 1,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.4:46195 (size: 4.2 KB, free: 143.2 MB)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 91 ms on 172.17.0.4 (1/2)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 102 ms on 172.17.0.4 (2/2)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
16/05/02 01:58:07 INFO scheduler.DAGScheduler: ResultStage 3 (collect at /tmp/data/main.py:5) finished in 0.104 s
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Job 1 finished: collect at /tmp/data/main.py:5, took 0.119096 s
('user_0', ('item_1', 'item_2'))
('user_0', ('item_1', 'item_2'))
('user_0', ('item_1', 'item_2'))
('user_0', ('item_2', 'item_1'))
('user_0', ('item_2', 'item_1'))
('user_0', ('item_1', 'item_2'))
('user_0', ('item_1', 'item_2'))
('user_0', ('item_2', 'item_1'))
('user_0', ('item_1', 'item_2'))
step3: (user_id, (item1, item2))
16/05/02 01:58:07 INFO spark.SparkContext: Starting job: collect at /tmp/data/main.py:5
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Registering RDD 9 (groupByKey at /tmp/data/main.py:37)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Got job 2 (collect at /tmp/data/main.py:5) with 2 output partitions
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (collect at /tmp/data/main.py:5)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 5)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[9] at groupByKey at /tmp/data/main.py:37), which has no missing parents
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.5 KB, free 270.0 KB)
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.7 KB, free 275.7 KB)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.3:36614 (size: 5.7 KB, free: 511.1 MB)
16/05/02 01:58:07 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (PairwiseRDD[9] at groupByKey at /tmp/data/main.py:37)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, 172.17.0.4, partition 0,NODE_LOCAL, 1930 bytes)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7, 172.17.0.4, partition 1,NODE_LOCAL, 1930 bytes)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.4:46195 (size: 5.7 KB, free: 143.2 MB)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 97 ms on 172.17.0.4 (1/2)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 103 ms on 172.17.0.4 (2/2)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
16/05/02 01:58:07 INFO scheduler.DAGScheduler: ShuffleMapStage 5 (groupByKey at /tmp/data/main.py:37) finished in 0.105 s
16/05/02 01:58:07 INFO scheduler.DAGScheduler: looking for newly runnable stages
16/05/02 01:58:07 INFO scheduler.DAGScheduler: running: Set()
16/05/02 01:58:07 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 6)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: failed: Set()
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (PythonRDD[12] at collect at /tmp/data/main.py:5), which has no missing parents
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.8 KB, free 281.5 KB)
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KB, free 285.2 KB)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.3:36614 (size: 3.8 KB, free: 511.1 MB)
16/05/02 01:58:07 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (PythonRDD[12] at collect at /tmp/data/main.py:5)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, 172.17.0.4, partition 0,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, 172.17.0.4, partition 1,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.4:46195 (size: 3.8 KB, free: 143.2 MB)
16/05/02 01:58:07 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.17.0.4:54084
16/05/02 01:58:07 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 150 bytes
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 94 ms on 172.17.0.4 (1/2)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 94 ms on 172.17.0.4 (2/2)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
16/05/02 01:58:07 INFO scheduler.DAGScheduler: ResultStage 6 (collect at /tmp/data/main.py:5) finished in 0.095 s
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Job 2 finished: collect at /tmp/data/main.py:5, took 0.231666 s
(('item_1', 'item_2'), <pyspark.resultiterable.ResultIterable object at 0x7f72adef4710>)
(('item_2', 'item_1'), <pyspark.resultiterable.ResultIterable object at 0x7f72adef47f0>)
step4: ((item1, item2), [user])
16/05/02 01:58:07 INFO spark.SparkContext: Starting job: collect at /tmp/data/main.py:49
16/05/02 01:58:07 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 150 bytes
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Got job 3 (collect at /tmp/data/main.py:49) with 2 output partitions
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (collect at /tmp/data/main.py:49)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Missing parents: List()
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (PythonRDD[13] at collect at /tmp/data/main.py:49), which has no missing parents
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 291.5 KB)
16/05/02 01:58:07 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.1 KB, free 295.6 KB)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.3:36614 (size: 4.1 KB, free: 511.1 MB)
16/05/02 01:58:07 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (PythonRDD[13] at collect at /tmp/data/main.py:49)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, 172.17.0.4, partition 0,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.0 (TID 11, 172.17.0.4, partition 1,NODE_LOCAL, 1941 bytes)
16/05/02 01:58:07 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.4:46195 (size: 4.1 KB, free: 143.2 MB)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.0 (TID 11) in 78 ms on 172.17.0.4 (1/2)
16/05/02 01:58:07 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 83 ms on 172.17.0.4 (2/2)
16/05/02 01:58:07 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
16/05/02 01:58:07 INFO scheduler.DAGScheduler: ResultStage 9 (collect at /tmp/data/main.py:49) finished in 0.085 s
16/05/02 01:58:07 INFO scheduler.DAGScheduler: Job 3 finished: collect at /tmp/data/main.py:49, took 0.113830 s
OUTPUT: Items item_1 and item_2 were co-clicked 6 times.
OUTPUT: Items item_2 and item_1 were co-clicked 3 times.
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
16/05/02 01:58:07 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
16/05/02 01:58:07 INFO ui.SparkUI: Stopped Spark web UI at http://172.17.0.3:4040
16/05/02 01:58:07 INFO cluster.SparkDeploySchedulerBackend: Shutting down all executors
16/05/02 01:58:07 INFO cluster.SparkDeploySchedulerBackend: Asking each executor to shut down
16/05/02 01:58:07 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/05/02 01:58:07 INFO storage.MemoryStore: MemoryStore cleared
16/05/02 01:58:07 INFO storage.BlockManager: BlockManager stopped
16/05/02 01:58:07 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
16/05/02 01:58:07 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/05/02 01:58:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
16/05/02 01:58:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
16/05/02 01:58:07 INFO spark.SparkContext: Successfully stopped SparkContext
16/05/02 01:58:07 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
16/05/02 01:58:08 INFO util.ShutdownHookManager: Shutdown hook called
16/05/02 01:58:08 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-8b650f5f-e411-46bb-b93e-b0d8a1c54200/pyspark-d27ccf38-48a4-4e22-a7b2-51843f744335
16/05/02 01:58:08 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-8b650f5f-e411-46bb-b93e-b0d8a1c54200
16/05/02 01:58:08 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-8b650f5f-e411-46bb-b93e-b0d8a1c54200/httpd-6ab0461a-9644-45d1-a3e2-057385a40ada
